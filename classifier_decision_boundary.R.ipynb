{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Developed by: Adriano Henrique Cantão & José Augusto Baranauskas\n",
    "First released on August, 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installing needed packages - if not installed already"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "install_packages <- function(packs) {\n",
    "  for (pack in packs){\n",
    "    if (!pack %in% installed.packages()) install.packages(pack)\n",
    "  }\n",
    "}\n",
    "install_packages(packs=c(\"ggplot2\",\"grid\",\"gridExtra\",\"mlbench\",\"caret\",\"e1071\",\n",
    "                        \"C50\",\"rpart\",\"randomForest\",\"nnet\",\"neuralnet\",\"mlogit\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the plot id and designing the final plot layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to get plot ids to arrange the plotting order in grid.arrange()\n",
    "select_grobs <- function(lay) {\n",
    "  id <- unique(c(t(lay))) \n",
    "  id[!is.na(id)]\n",
    "} \n",
    "\n",
    "#function to design the plot layout\n",
    "choose_layout <- function(size){\n",
    "  if(size == 2){\n",
    "    hlay <- rbind(c(1, 2))\n",
    "  }else if(size == 3){\n",
    "    hlay <- rbind(c(1, NA),\n",
    "                  c(2, 3))\n",
    "  }else if(size == 4){\n",
    "    hlay <- rbind(c(1, 2),\n",
    "                  c(3, 4))\n",
    "  }else if(size == 5){\n",
    "    hlay <- rbind(c( 1,2,3),\n",
    "                  c(NA,4,5))\n",
    "  }else if(size == 6){\n",
    "    hlay <- rbind(c(1,2,3),\n",
    "                  c(4,5,6))\n",
    "  }else if(size == 7){\n",
    "    hlay <- rbind(c( 1,2,3,4),\n",
    "                  c(NA,5,6,7))\n",
    "  }else if(size == 8){\n",
    "    hlay <- rbind(c(1,2,3,4),\n",
    "                  c(5,6,7,8))\n",
    "  }else if(size == 9){\n",
    "    hlay <- rbind(c( 1,2,3,4,5),\n",
    "                  c(NA,6,7,8,9))\n",
    "  }else if(size == 10){\n",
    "    hlay <- rbind(c(1,2,3,4,5 ),\n",
    "                  c(6,7,8,9,10))\n",
    "  }else {\n",
    "    print(\"It is configured only up to 10 plots in a single image. If you need more, add it right before this message.\")\n",
    "  }\n",
    "  return(hlay)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boundary <- function(models, dataset_name, inducer_name, k=1){ \n",
    "  set.seed(2020)\n",
    "  file_name <- gsub(\"\\\\([\\\\w\\\\d\\\\s\\\\=\\\\.,]*\\\\)\", \"\", dataset_name, perl=TRUE, ignore.case=TRUE)\n",
    "  file_name <- paste( file_name, \".\", inducer_name, \".\", file_extension, sep=\"\")\n",
    "\n",
    "  #uncomment bellow to see de details while the script is running \n",
    "#   print( paste(\"Dataset.: \",dataset_name, sep=\"\") )\n",
    "#   print( paste(\"Filename: \",file_name, sep=\"\") )\n",
    "#   cat(\"\\n\")\n",
    "  \n",
    "  #creating and preparing the dataset\n",
    "  p <- eval(parse(text = dataset_name))\n",
    "  data <- data.frame(p$x[,1], p$x[,2], p$class)\n",
    "  names(data) <- c(\"x1\",\"x2\",\"class\")\n",
    "  \n",
    "  #splittng data into train(data) and test\n",
    "  sample_index <- sample(seq_len(nrow(data)), size = floor(nrow(data) / 2), replace = FALSE)\n",
    "  test <- data[-sample_index, ]\n",
    "  data <- data[sample_index, ]\n",
    "  \n",
    "  plot_title <- \"Dataset\"\n",
    "  #replacing the text 'samples' by the variable value and save the whole string as title\n",
    "  plot_subtitle <- gsub(\"samples\", samples/2, dataset_name)\n",
    "  \n",
    "  #preparing background grid area\n",
    "  x1_min <- min(p$x[,1])-0.2\n",
    "  x1_max <- max(p$x[,1])+0.2\n",
    "  x2_min <- min(p$x[,2])-0.2\n",
    "  x2_max <- max(p$x[,2])+0.2\n",
    "  \n",
    "  #all grids will have ~150 steps. *-1 to make the number positive\n",
    "  grid_step <- ((x1_min - x1_max) / 150 ) * -1\n",
    "  #hs <- 0.05 #changed to 'grid_step' as a variable...\n",
    "  grid <- as.matrix(expand.grid(seq(x1_min, x1_max, by = grid_step), seq(x2_min, x2_max, by = grid_step)))\n",
    "  grid.df <- as.data.frame(grid)\n",
    "  colnames(grid.df) <- colnames(data[,1:2])\n",
    "  \n",
    "  #saving the raw dataset - without any model\n",
    "  plots <- list()\n",
    "  plots[[length(plots)+1]] <- \n",
    "    ggplot(data) + \n",
    "    geom_point(aes(x=x1, y=x2, color = as.character(class)), size = 1) + \n",
    "    theme_bw(base_size = 15) +\n",
    "    xlim(x1_min, x1_max) + \n",
    "    ylim(x2_min, x2_max) +\n",
    "    labs(title = plot_title, subtitle = plot_subtitle) +\n",
    "    coord_fixed(ratio = 0.8) +\n",
    "    theme(axis.ticks=element_blank(), panel.grid.major = element_blank(), panel.grid.minor = element_blank(), \n",
    "          axis.text=element_blank(), axis.title=element_blank(), legend.position = 'none',\n",
    "          plot.title  = element_text(size = 15, face = \"bold\", hjust = 0.5, vjust = -1, color = \"black\"),\n",
    "          plot.subtitle=element_text(size = 10, face =\"plain\", hjust = 0.1, vjust = -1, color = \"brown\"))\n",
    "  Z <- NULL\n",
    "  require(caret)\n",
    "  i = 0\n",
    "  for(mod in models){\n",
    "    i = i+1\n",
    "    model <- eval(parse(text=mod))\n",
    "    #getting accuracy in train data\n",
    "    prediction_train <- predict(model, data[,1:2],type = \"class\")\n",
    "    conf_matrix_train <- table(prediction_train, data[,3])\n",
    "    accuracy_train <- (sum(diag(conf_matrix_train)) / sum(conf_matrix_train)) * 100\n",
    "    #getting accuracy in test data\n",
    "    prediction_test <- predict(model, test[,1:2],type = \"class\")\n",
    "    conf_matrix_test <- table(prediction_test, test[,3])\n",
    "    accuracy_test <- (sum(diag(conf_matrix_test)) / sum(conf_matrix_test)) * 100\n",
    "    plot_title <- paste0(inducer_name, k[i])\n",
    "    plot_subtitle <- paste(\"training accuracy:\",round(accuracy_train,2),\"% - test accuracy:\",round(accuracy_test,2),\"%\")\n",
    "    Z <- predict(model, grid.df, type = \"class\")\n",
    "      \n",
    "    plots[[length(plots)+1]] <- \n",
    "      ggplot()+\n",
    "      geom_raster(aes_string(x = grid[,1],y = grid[,2],fill= as.factor(Z) ), alpha = 0.3, show.legend = F)+ \n",
    "      geom_point(data = data, aes(x=x1, y=x2, color = as.character(class)), size = 1) + \n",
    "      theme_bw(base_size = 15) +\n",
    "      labs(title = plot_title, subtitle = plot_subtitle) +\n",
    "      coord_fixed(ratio = 0.8) + \n",
    "      theme(axis.ticks=element_blank(), panel.grid.major = element_blank(), panel.grid.minor = element_blank(), \n",
    "            axis.text=element_blank(), axis.title=element_blank(), legend.position = 'none', \n",
    "            plot.title  = element_text(size = 15, face = \"bold\", hjust = 0.5, vjust = -1, color = \"black\"),\n",
    "            plot.subtitle=element_text(size = 10, face =\"plain\", hjust = 0.1, vjust = -1, color = \"brown\"))\n",
    "  }\n",
    "  #arrange the plots according to the number of plots\n",
    "  hlay <- choose_layout(length(plots))\n",
    "  #arranging many plots inside a single one - the line bellow print the output \n",
    "  grid.arrange(grobs=plots[select_grobs(hlay)], layout_matrix=hlay)\n",
    "  #saving to file\n",
    "  if(save_plot_to_file == TRUE){\n",
    "    ggsave(filename = file_name,\n",
    "           plot = grid.arrange(grobs=plots[select_grobs(hlay)], layout_matrix=hlay),\n",
    "           path = outputPath,\n",
    "           width = 297,\n",
    "           height = 210,\n",
    "           units = \"mm\")\n",
    "  }else{\n",
    "     print(\"NOT SAVING\")\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "get_boundaries <- function(dataset_names,\n",
    "                           knn,\n",
    "                           svm,\n",
    "                           trees,\n",
    "                           nb,\n",
    "                           ann_neu,\n",
    "                           ann_its,\n",
    "                           ann_fit=FALSE){\n",
    "  require(mlbench)\n",
    "  require(ggplot2)\n",
    "  require(caret)\n",
    "  require(lattice)\n",
    "  require(gridExtra)\n",
    "  \n",
    "  for(dataset_name in dataset_names){\n",
    "    if(knn == TRUE){\n",
    "      require(caret)\n",
    "      inducer_name <- \"KNN \"\n",
    "      k <- c(1, 3, 5, 10, 30)  #k[i]\n",
    "      models <- c( \"knn3(class ~ ., data=data, k = k[1])\",\n",
    "                   \"knn3(class ~ ., data=data, k = k[2])\",\n",
    "                   \"knn3(class ~ ., data=data, k = k[3])\",\n",
    "                   \"knn3(class ~ ., data=data, k = k[4])\",\n",
    "                   \"knn3(class ~ ., data=data, k = k[5])\")\n",
    "      boundary(models, dataset_name, inducer_name, k)\n",
    "    }\n",
    "    #----------------------------------------------------------------\n",
    "    if(svm == TRUE){\n",
    "      require(e1071) #cart\n",
    "      inducer_name <- \"SVM \"\n",
    "      k <- c(\"linear\", \"Polynomial\", \"Radial\", \"Sigmoid\")\n",
    "      models <- c( \"svm(class ~ ., data=data, kernel='linear')\",\n",
    "                   \"svm(class ~ ., data=data, kernel='polynomial')\",\n",
    "                   \"svm(class ~ ., data=data, kernel='radial')\",\n",
    "                   \"svm(class ~ ., data=data, kernel='sigmoid')\")\n",
    "      boundary(models, dataset_name, inducer_name, k)\n",
    "    }\n",
    "    #----------------------------------------------------------------\n",
    "    if(trees == TRUE){\n",
    "      require(C50)\n",
    "      require(rpart)\n",
    "      library(randomForest)\n",
    "      inducer_name <- \"Trees \"\n",
    "      k <- c(\"C.50\",\"CART\", \"Random Forest 3 trees\", \"Random Forest 128 trees\")\n",
    "      models <- c(\"C5.0(class ~ ., data=data)\",\n",
    "                  \"rpart(class ~ ., data=data)\",\n",
    "                  \"randomForest(class ~ ., data=data, ntree=3)\",\n",
    "                  \"randomForest(class ~ ., data=data, ntree=128)\")\n",
    "      boundary(models, dataset_name, inducer_name, k)\n",
    "    }\n",
    "    #----------------------------------------------------------------\n",
    "    if(nb == TRUE){\n",
    "      require(e1071)\n",
    "      inducer_name <- \"Naive Bayes\"\n",
    "      models <- \"naiveBayes(class ~ ., data=data)\"\n",
    "      boundary(models, dataset_name, inducer_name, k=\"\")\n",
    "    }\n",
    "    #----------------------------------------------------------------\n",
    "    if(ann_neu == TRUE){ #Artificial Neural Network: [qty neurons]\n",
    "      require(nnet)\n",
    "      inducer_name <- \"ANN_iters=100_neurons=\"\n",
    "      k <- c(1, 10, 100, 500, 1000)\n",
    "      models <- c(\"nnet(class ~ ., data=data, size = k[1], maxit = 100, MaxNWts = 10000, trace = FALSE)\",\n",
    "                  \"nnet(class ~ ., data=data, size = k[2], maxit = 100, MaxNWts = 10000, trace = FALSE)\",\n",
    "                  \"nnet(class ~ ., data=data, size = k[3], maxit = 100, MaxNWts = 10000, trace = FALSE)\",\n",
    "                  \"nnet(class ~ ., data=data, size = k[4], maxit = 100, MaxNWts = 10000, trace = FALSE)\",\n",
    "                  \"nnet(class ~ ., data=data, size = k[5], maxit = 100, MaxNWts = 10000, trace = FALSE)\")\n",
    "      boundary(models, dataset_name, inducer_name, k=k)\n",
    "    }\n",
    "    #----------------------------------------------------------------\n",
    "    if(ann_its == TRUE){ #Artificial Neural Network: [qty iterations]\n",
    "      require(nnet)\n",
    "      inducer_name <- \"ANN_neurons=10_iters=\"\n",
    "      k <- c(10, 100, 500, 1000, 10000)\n",
    "      models <- c(\"nnet(class ~ ., data=data, size = 10, maxit = k[1], MaxNWts = 10000, trace = FALSE)\",\n",
    "                  \"nnet(class ~ ., data=data, size = 10, maxit = k[2], MaxNWts = 10000, trace = FALSE)\",\n",
    "                  \"nnet(class ~ ., data=data, size = 10, maxit = k[3], MaxNWts = 10000, trace = FALSE)\",\n",
    "                  \"nnet(class ~ ., data=data, size = 10, maxit = k[4], MaxNWts = 10000, trace = FALSE)\",\n",
    "                  \"nnet(class ~ ., data=data, size = 10, maxit = k[5], MaxNWts = 10000, trace = FALSE)\")\n",
    "      boundary(models, dataset_name, inducer_name, k=k)\n",
    "    }\n",
    "#-----------------------not-working-----------------------------------\n",
    "    if(ann_fit == TRUE){ #Artificial Neural Network: [fitting]\n",
    "      print(\"ENTREI\")\n",
    "#       require(nnet)\n",
    "#       inducer_name <- \"ANN_neurons=100_fitting=\"\n",
    "#       k <- c(\"logistic\", \"softmax\", \"linout\", \"censored\", \"entropy\")\n",
    "#       models <- c(\"nnet(class ~ ., data=data, size = 100, maxit = 1000)\",\n",
    "#                   \"nnet(class ~ ., data=data, size = 100, maxit = 1000, softmax  = TRUE)\",\n",
    "#                   \"nnet(class ~ ., data=data, size = 100, maxit = 1000, linout   = TRUE)\",\n",
    "#                   \"nnet(class ~ ., data=data, size = 100, maxit = 1000, censored = TRUE)\",\n",
    "#                   \"nnet(class ~ ., data=data, size = 100, maxit = 1000, entropy  = TRUE)\")\n",
    "#       boundary(models, dataset_name, inducer_name, k=k)\n",
    "    }\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use a low number of samples to have a better view of the boundaries\n",
    "samples     <- 200\n",
    "outputPath  <- \"\"\n",
    "\n",
    "save_plot_to_file <- FALSE #if false, will plot, but not save\n",
    "file_extension <- \"pdf\"\n",
    "\n",
    "#High values of standard deviation (sd) leads to very mixed classes\n",
    "dataset_names <- c(\"mlbench.2dnormals(n=samples, cl=2)\",\n",
    "                  \"mlbench.cassini(n=samples)\",\n",
    "                  \"mlbench.hypercube(n=samples, d=2, sd=0.3)\",\n",
    "                  \"mlbench.circle(n=samples, d=2)\",\n",
    "                  \"mlbench.ringnorm(n=samples, d=2)\",\n",
    "                  \"mlbench.shapes(n=samples)\",\n",
    "                  \"mlbench.simplex(n=samples, d=2, sd = 0.3)\",\n",
    "                  \"mlbench.smiley(n=samples, sd1 = 0.1, sd2 = 0.3)\",\n",
    "                  #\"mlbench.spirals(n=samples, cycles=1, sd=0.0)\",\n",
    "                  \"mlbench.spirals(n=samples, cycles=3, sd=0.0)\",\n",
    "                  \"mlbench.threenorm(n=samples, d=2)\",\n",
    "                  \"mlbench.twonorm(n=samples, d=2)\",\n",
    "                  \"mlbench.xor(n=samples, d=2)\")\n",
    "\n",
    "#double samples then split in half for testing accuracy\n",
    "samples <- samples * 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running the script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "get_boundaries(dataset_names,\n",
    "               knn     <- TRUE,  #K-nearest neighbors\n",
    "               svm     <- TRUE,  #Support-vector machine\n",
    "               trees   <- TRUE,  #tree-based\n",
    "               nb      <- TRUE,  #Naive Bayes\n",
    "               ann_neu <- TRUE,  #Artificial neural network increasing neurons\n",
    "               ann_its <- TRUE,  #Artificial neural network increasing iterations\n",
    "               ann_fit <- FALSE) #Artificial neural network changing functions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
